{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "AVG_EARTH_RADIUS = 6372.8\n",
    "\n",
    "def haversine(point1, point2):\n",
    "\n",
    "    # извлекаем долготу и широту\n",
    "    lat1, lng1 = point1\n",
    "    lat2, lng2 = point2\n",
    "\n",
    "    # переводим все эти значения в радианы\n",
    "    lat1, lng1, lat2, lng2 = map(radians, (lat1, lng1, lat2, lng2))\n",
    "\n",
    "    # вычисляем расстояние по формуле\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = sin(lat * 0.5) ** 2 + cos(lat1) * cos(lat2) * sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * asin(sqrt(d))\n",
    "    return h \n",
    "\n",
    "import numpy as np\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km =  6372.8 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_csv(f'points{file_id}.txt', header=None, names=[\"raw_data\"])\n",
    "points[['Latitude', 'raw_data']]= points[\"raw_data\"].str.split(n = 1, expand = True)\n",
    "points[['Longitude', 'raw_data']]= points[\"raw_data\"].str.split(n = 1, expand = True)\n",
    "points.rename(columns={'raw_data': 'city'}, inplace=True)\n",
    "points = points.astype({'Latitude': 'float', \n",
    "                        'Longitude': 'float'})\n",
    "\n",
    "# # Делает город индексом #\n",
    "# points.index=points.city\n",
    "# del points[\"city\"]\n",
    "# points.index.name = None\n",
    "\n",
    "# points_dict := {city: (Latitude, Longitude)}\n",
    "points_dict = points.set_index('city').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pd.read_csv(f'graph{file_id}.txt', header=None, index_col=None, names=[\"raw_data\"])\n",
    "graph[['node1', 'node2']] = graph[\"raw_data\"].str.split(\" --- \", n = 1, expand = True)\n",
    "del graph['raw_data']\n",
    "# graph[\"color\"] = \"red\"\n",
    "# graph[\"estimate\"] = 1\n",
    "# graph[\"trail\"] = 0.18\n",
    "# graph[\"distance\"] = 10\n",
    "\n",
    "# добавляю дистанцию\n",
    "graph = pd.merge(graph, points, right_on=\"city\", left_on=\"node1\")\n",
    "del graph['city']\n",
    "graph = pd.merge(graph, points, right_on=\"city\", left_on=\"node2\", suffixes=('_node1', \"_node2\"))\n",
    "del graph['city']\n",
    "graph['weight'] = haversine_np(\n",
    "    graph['Latitude_node1'],  graph['Longitude_node1'], \n",
    "    graph['Latitude_node2'],  graph['Longitude_node2']\n",
    ")\n",
    "del graph['Latitude_node1'],  graph['Longitude_node1'], \n",
    "del graph['Latitude_node2'],  graph['Longitude_node2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаю граф для поиска в нём не связанных мини-графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "G.add_nodes_from(points.city.to_list())\n",
    "weighted_edges_from = graph.values\n",
    "\n",
    "G.add_weighted_edges_from(weighted_edges_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахожу не связанные мини-графы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено связанных графов: 1630\n",
      "Wall time: 632 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "def connected_components_list(G):\n",
    "    viwes = []\n",
    "    components = nx.connected_components(G)\n",
    "    result = []\n",
    "    for nodes in components:\n",
    "        for node in nodes:\n",
    "            if node not in viwes:\n",
    "                result.append(tuple(nodes))\n",
    "                viwes.extend(nodes)\n",
    "    return result\n",
    "\n",
    "\n",
    "connected_components = connected_components_list(G)\n",
    "print(\"Найдено связанных графов:\", len(connected_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components_index_dict = {} # {int[index]: List[mini-graph]}\n",
    "for i in range(len(connected_components)):\n",
    "    connected_components_index_dict[i] = connected_components[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаю граф, в котором есть все связи межу мини-графами,\n",
    "* вершины: названия мини-графов\n",
    "* рёбра: дистанция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_graph = []\n",
    "viwes_graph_idx = []\n",
    "C = 0\n",
    "# 18 484 363 итераций \n",
    "for graph_index1, graph_index2 in combinations(connected_components_index_dict.keys(), 2):\n",
    "    min_weight = \"None\"\n",
    "    graph1, graph2 = connected_components_index_dict[graph_index1], connected_components_index_dict[graph_index2]\n",
    "    for node1 in  graph1:\n",
    "        for node2 in  graph2:\n",
    "            if min_weight == \"None\":\n",
    "                min_weight = haversine(points_dict[node1], points_dict[node2])\n",
    "            else:\n",
    "                min_weight = min(min_weight, haversine(points_dict[node1], points_dict[node2]))\n",
    "    new_graph.append([graph_index1, graph_index2, min_weight])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck_graph = pd.DataFrame(new_graph)\n",
    "fuck_graph.rename(\n",
    "    columns={0: 'node1',\n",
    "             1: \"node2\",\n",
    "             2: \"weight\"},\n",
    "             inplace=True)\n",
    "fuck_graph = fuck_graph.astype({\n",
    "    'node1': 'str', \n",
    "    'node2': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fucking_G=nx.Graph()\n",
    "Fucking_G.add_nodes_from(list(map(str, connected_components_index_dict.keys())))\n",
    "weighted_edges_from = fuck_graph.values\n",
    "\n",
    "Fucking_G.add_weighted_edges_from(weighted_edges_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахожу minimum spanning tree от подученного графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итог: 170775.80728912327\n"
     ]
    }
   ],
   "source": [
    "fucking_mst = nx.minimum_spanning_tree(Fucking_G)\n",
    "result_sum = 0\n",
    "for u,v,d in fucking_mst.edges(data=True):\n",
    "    result_sum+=d['weight']\n",
    "print('Итог:', result_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
